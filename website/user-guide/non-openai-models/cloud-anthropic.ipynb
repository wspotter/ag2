{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Anthropic Claude\n",
    "\n",
    "Claude is a family of large language models developed by Anthropic and designed to revolutionize the way you interact with AI. Claude excels at a wide variety of tasks involving language, reasoning, analysis, coding, and more. The models are highly capable, easy to use, and can be customized to suit your needs.\n",
    "\n",
    "In this notebook, we demonstrate how to use Anthropic Claude model for AgentChat in AG2.\n",
    "\n",
    "## Features\n",
    "\n",
    "- Function/tool calling\n",
    "- Structured Outputs ([Notebook example](https://docs.ag2.ai/docs/use-cases/notebooks/notebooks/agentchat_structured_outputs))\n",
    "- Token usage and cost correctly as per Anthropic's API costs (as of December 2024)\n",
    "\n",
    "## Requirements\n",
    "To use Anthropic Claude with AG2, first you need to install the `ag2[anthropic]` package.\n",
    "\n",
    "To try out the function call feature of Claude model, you need to install `anthropic>=0.23.1`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install ag2[\"anthropic\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Note:** If you have been using `autogen` or `pyautogen`, all you need to do is upgrade it using:  \n",
    "> ```bash\n",
    "> pip install -U autogen[anthropic]\n",
    "> ```\n",
    "> or  \n",
    "> ```bash\n",
    "> pip install -U pyautogen[anthropic]\n",
    "> ```\n",
    "> as `pyautogen`, `autogen`, and `ag2` are aliases for the same PyPI package.  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set the config for the Anthropic API\n",
    "\n",
    "You can add any parameters that are needed for the custom model loading in the same configuration list.\n",
    "\n",
    "It is important to add the `api_type` field and set it to a string that corresponds to the client type used: `anthropic`.\n",
    "\n",
    "Example:\n",
    "```\n",
    "[\n",
    "    {\n",
    "        \"model\": \"claude-3-5-sonnet-20240620\",\n",
    "        \"api_key\": \"your Anthropic API Key goes here\",\n",
    "        \"api_type\": \"anthropic\",\n",
    "    },\n",
    "    {\n",
    "        \"model\": \"claude-3-sonnet-20240229\",\n",
    "        \"api_key\": \"your Anthropic API Key goes here\",\n",
    "        \"api_type\": \"anthropic\",\n",
    "        \"temperature\": 0.5,\n",
    "        \"top_p\": 0.2, # Note: It is recommended to set temperature or top_p but not both.\n",
    "        \"max_tokens\": 10000,\n",
    "    },\n",
    "    {\n",
    "        \"model\":\"claude-3-opus-20240229\",\n",
    "        \"api_key\":\"your api key\",\n",
    "        \"api_type\":\"anthropic\",\n",
    "    },\n",
    "    {\n",
    "        \"model\":\"claude-2.0\",\n",
    "        \"api_key\":\"your api key\",\n",
    "        \"api_type\":\"anthropic\",\n",
    "    },\n",
    "    {\n",
    "        \"model\":\"claude-2.1\",\n",
    "        \"api_key\":\"your api key\",\n",
    "        \"api_type\":\"anthropic\",\n",
    "    },\n",
    "    {\n",
    "        \"model\":\"claude-3.0-haiku\",\n",
    "        \"api_key\":\"your api key\",\n",
    "        \"api_type\":\"anthropic\",\n",
    "    },\n",
    "]\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Alternative\n",
    "\n",
    "As an alternative to the api_key key and value in the config, you can set the environment variable `ANTHROPIC_API_KEY` to your Anthropic API key.\n",
    "\n",
    "Linux/Mac:\n",
    "```\n",
    "export ANTHROPIC_API_KEY=\"your Anthropic API key here\"\n",
    "```\n",
    "Windows:\n",
    "```\n",
    "set ANTHROPIC_API_KEY=your_anthropic_api_key_here\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "from typing_extensions import Annotated\n",
    "\n",
    "import autogen\n",
    "\n",
    "config_list_claude = [\n",
    "    {\n",
    "        # Choose your model name.\n",
    "        \"model\": \"claude-3-5-sonnet-20240620\",\n",
    "        # You need to provide your API key here.\n",
    "        \"api_key\": os.getenv(\"ANTHROPIC_API_KEY\"),\n",
    "        \"api_type\": \"anthropic\",\n",
    "    }\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Alternative Anthropic VertexAI Client (GCP)\n",
    "\n",
    "To use the Anthropic VertexAI client in AutoGen, you need to configure it for use with Google Cloud Platform (GCP). Ensure you have the necessary project credentials and install the required package.\n",
    "\n",
    "Configuration\n",
    "\n",
    "The following configuration example demonstrates how to set up Anthropic VertexAI:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "config_list_vertexai = [\n",
    "    {\n",
    "        \"model\": \"claude-3-5-sonnet-20240620-v1:0\",\n",
    "        \"gcp_project_id\": \"your_project_id\",\n",
    "        \"gcp_region\": \"us-west-2\",  # Replace with your GCP region\n",
    "        \"gcp_auth_token\": None,  # Optional: If not passed, Google Default Authentication will be used\n",
    "        \"api_type\": \"anthropic\",\n",
    "    }\n",
    "]\n",
    "\n",
    "assistant = autogen.AssistantAgent(\n",
    "    \"assistant\",\n",
    "    llm_config={\n",
    "        \"config_list\": config_list_vertexai,\n",
    "    },\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Alternative Anthropic VertexAI Client (Google Default Authentication)\n",
    "\n",
    "If the `gcp_auth_token` is not provided in the configuration, the client will use Google’s default authentication mechanism. This requires the appropriate credentials to be configured in your environment, such as:\n",
    "\n",
    "- Service account key: You can set the `GOOGLE_APPLICATION_CREDENTIALS` environment variable to point to your service account key file.\n",
    "- Cloud Shell or GCP Compute Engine: When running in a GCP-managed environment, default authentication is automatically applied.\n",
    "\n",
    "\n",
    "Example of setting up the environment variable:\n",
    "\n",
    "export GOOGLE_APPLICATION_CREDENTIALS=\"/path/to/your/service-account-key.json\"\n",
    "\n",
    "This allows seamless integration without explicitly specifying the authentication token in your code."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Two-agent Coding Example"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Construct Agents\n",
    "\n",
    "Construct a simple conversation between a User proxy and an ConversableAgent based on Claude-3 model.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "assistant = autogen.AssistantAgent(\n",
    "    \"assistant\",\n",
    "    llm_config={\n",
    "        \"config_list\": config_list_claude,\n",
    "    },\n",
    ")\n",
    "\n",
    "user_proxy = autogen.UserProxyAgent(\n",
    "    \"user_proxy\",\n",
    "    human_input_mode=\"NEVER\",\n",
    "    code_execution_config={\n",
    "        \"work_dir\": \"coding\",\n",
    "        \"use_docker\": False,\n",
    "    },\n",
    "    is_termination_msg=lambda x: x.get(\"content\", \"\") and x.get(\"content\", \"\").rstrip().endswith(\"TERMINATE\"),\n",
    "    max_consecutive_auto_reply=1,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initiate Chat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_proxy.initiate_chat(\n",
    "    assistant, message=\"Write a python program to print the first 10 numbers of the Fibonacci sequence.\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tool Call Example with the Latest Anthropic API \n",
    "Anthropic just announced that tool use is now supported in the Anthropic API. To use this feature, please install `anthropic>=0.23.1`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Register the function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "@user_proxy.register_for_execution()  # Decorator factory for registering a function to be executed by an agent\n",
    "@assistant.register_for_llm(\n",
    "    name=\"get_weather\", description=\"Get the current weather in a given location.\"\n",
    ")  # Decorator factory for registering a function to be used by an agent\n",
    "def preprocess(location: Annotated[str, \"The city and state, e.g. Toronto, ON.\"]) -> str:\n",
    "    return \"Absolutely cloudy and rainy\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_proxy.initiate_chat(\n",
    "    assistant,\n",
    "    message=\"What's the weather in Toronto?\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Group Chat Example with both Claude and GPT Agents "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A group chat with GPT-4 as the judge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from autogen import AssistantAgent, GroupChat, GroupChatManager, UserProxyAgent\n",
    "\n",
    "config_list_gpt4 = [\n",
    "    {\n",
    "        # Choose your model name.\n",
    "        \"model\": \"gpt-4\",\n",
    "        # You need to provide your API key here.\n",
    "        \"api_key\": os.getenv(\"OPENAI_API_KEY\"),\n",
    "        \"api_type\": \"openai\",\n",
    "    }\n",
    "]\n",
    "\n",
    "\n",
    "config_list_gpt35 = [\n",
    "    {\n",
    "        # Choose your model name.\n",
    "        \"model\": \"gpt-3.5-turbo\",\n",
    "        # You need to provide your API key here.\n",
    "        \"api_key\": os.getenv(\"OPENAI_API_KEY\"),\n",
    "        \"api_type\": \"openai\",\n",
    "    }\n",
    "]\n",
    "\n",
    "alice = AssistantAgent(\n",
    "    \"Openai_agent\",\n",
    "    system_message=\"You are from OpenAI. You make arguments to support your company's position.\",\n",
    "    llm_config={\n",
    "        \"config_list\": config_list_gpt4,\n",
    "    },\n",
    ")\n",
    "\n",
    "bob = autogen.AssistantAgent(\n",
    "    \"Anthropic_agent\",\n",
    "    system_message=\"You are from Anthropic. You make arguments to support your company's position.\",\n",
    "    llm_config={\n",
    "        \"config_list\": config_list_claude,\n",
    "    },\n",
    ")\n",
    "\n",
    "charlie = AssistantAgent(\n",
    "    \"Research_Assistant\",\n",
    "    system_message=\"You are a helpful assistant to research the latest news and headlines.\",\n",
    "    llm_config={\n",
    "        \"config_list\": config_list_gpt35,\n",
    "    },\n",
    ")\n",
    "\n",
    "dan = AssistantAgent(\n",
    "    \"Judge\",\n",
    "    system_message=\"You are a judge. You will evaluate the arguments and make a decision on which one is more convincing.\",\n",
    "    llm_config={\n",
    "        \"config_list\": config_list_gpt4,\n",
    "    },\n",
    ")\n",
    "\n",
    "code_interpreter = UserProxyAgent(\n",
    "    \"code-interpreter\",\n",
    "    human_input_mode=\"NEVER\",\n",
    "    code_execution_config={\n",
    "        \"work_dir\": \"coding\",\n",
    "        \"use_docker\": False,\n",
    "    },\n",
    "    default_auto_reply=\"\",\n",
    "    is_termination_msg=lambda x: x.get(\"content\", \"\").find(\"TERMINATE\") >= 0,\n",
    ")\n",
    "\n",
    "\n",
    "@code_interpreter.register_for_execution()  # Decorator factory for registering a function to be executed by an agent\n",
    "@charlie.register_for_llm(\n",
    "    name=\"get_headlines\", description=\"Get the headline of a particular day.\"\n",
    ")  # Decorator factory for registering a function to be used by an agent\n",
    "def get_headlines(headline_date: Annotated[str, \"Date in MMDDYY format, e.g., 06192024\"]) -> str:\n",
    "    mock_news = {\n",
    "        \"06202024\": \"OpenAI competitor Anthropic announces its most powerful AI yet.\",\n",
    "        \"06192024\": \"OpenAI founder Sutskever sets up new AI company devoted to safe superintelligence.\",\n",
    "    }\n",
    "    return mock_news.get(headline_date, \"No news available for today.\")\n",
    "\n",
    "\n",
    "groupchat = GroupChat(\n",
    "    agents=[alice, bob, charlie, dan, code_interpreter],\n",
    "    messages=[],\n",
    "    allow_repeat_speaker=False,\n",
    "    max_round=10,\n",
    ")\n",
    "\n",
    "manager = GroupChatManager(\n",
    "    groupchat=groupchat,\n",
    "    llm_config={\n",
    "        \"config_list\": config_list_gpt4,\n",
    "    },\n",
    ")\n",
    "\n",
    "task = \"Analyze the potential of OpenAI and Anthropic to revolutionize the field of AI based on today's headlines. Today is 06202024.\"\n",
    "\n",
    "user_proxy = UserProxyAgent(\n",
    "    \"user_proxy\",\n",
    "    human_input_mode=\"NEVER\",\n",
    "    code_execution_config=False,\n",
    "    default_auto_reply=\"\",\n",
    "    # is_termination_msg=lambda x: True,\n",
    ")\n",
    "\n",
    "user_proxy.initiate_chat(manager, message=task)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Same group chat with Claude 3.5 Sonnet as the judge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dan = AssistantAgent(\n",
    "    \"Judge\",\n",
    "    system_message=\"You are a judge. You will evaluate the arguments and make a decision on which one is more convincing.\",\n",
    "    llm_config={\n",
    "        \"config_list\": config_list_claude,\n",
    "    },\n",
    ")\n",
    "\n",
    "groupchat = GroupChat(\n",
    "    agents=[alice, bob, charlie, dan, code_interpreter],\n",
    "    messages=[],\n",
    "    allow_repeat_speaker=False,\n",
    "    max_round=10,\n",
    ")\n",
    "\n",
    "manager = GroupChatManager(\n",
    "    groupchat=groupchat,\n",
    "    # is_termination_msg=lambda x: x.get(\"content\", \"\").find(\"TERMINATE\") >= 0,\n",
    "    llm_config={\n",
    "        \"config_list\": config_list_gpt4,\n",
    "    },\n",
    ")\n",
    "\n",
    "user_proxy.initiate_chat(manager, message=task)"
   ]
  }
 ],
 "metadata": {
  "front_matter": {
   "description": "Define and load a custom model",
   "tags": [
    "custom model"
   ]
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  },
  "vscode": {
   "interpreter": {
    "hash": "949777d72b0d2535278d3dc13498b2535136f6dfe0678499012e853ee9abcab1"
   }
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {
     "2d910cfd2d2a4fc49fc30fbbdc5576a7": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "454146d0f7224f038689031002906e6f": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_e4ae2b6f5a974fd4bafb6abb9d12ff26",
        "IPY_MODEL_577e1e3cc4db4942b0883577b3b52755",
        "IPY_MODEL_b40bdfb1ac1d4cffb7cefcb870c64d45"
       ],
       "layout": "IPY_MODEL_dc83c7bff2f241309537a8119dfc7555",
       "tabbable": null,
       "tooltip": null
      }
     },
     "577e1e3cc4db4942b0883577b3b52755": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_2d910cfd2d2a4fc49fc30fbbdc5576a7",
       "max": 1,
       "min": 0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_74a6ba0c3cbc4051be0a83e152fe1e62",
       "tabbable": null,
       "tooltip": null,
       "value": 1
      }
     },
     "6086462a12d54bafa59d3c4566f06cb2": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "74a6ba0c3cbc4051be0a83e152fe1e62": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "7d3f3d9e15894d05a4d188ff4f466554": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "b40bdfb1ac1d4cffb7cefcb870c64d45": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_f1355871cc6f4dd4b50d9df5af20e5c8",
       "placeholder": "​",
       "style": "IPY_MODEL_ca245376fd9f4354af6b2befe4af4466",
       "tabbable": null,
       "tooltip": null,
       "value": " 1/1 [00:00&lt;00:00, 44.69it/s]"
      }
     },
     "ca245376fd9f4354af6b2befe4af4466": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "dc83c7bff2f241309537a8119dfc7555": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "e4ae2b6f5a974fd4bafb6abb9d12ff26": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_6086462a12d54bafa59d3c4566f06cb2",
       "placeholder": "​",
       "style": "IPY_MODEL_7d3f3d9e15894d05a4d188ff4f466554",
       "tabbable": null,
       "tooltip": null,
       "value": "100%"
      }
     },
     "f1355871cc6f4dd4b50d9df5af20e5c8": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     }
    },
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
