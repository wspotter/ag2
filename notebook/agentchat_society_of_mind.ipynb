{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SocietyOfMindAgent\n",
    "\n",
    "TODO: reimplement the society of mind agent using `register_nested_chat` and move to the core library.\n",
    "\n",
    "This notebook demonstrates the SocietyOfMindAgent, which runs a group chat as an internal monologue, but appears to the external world as a single agent. This confers three distinct advantages:\n",
    "\n",
    "1. It provides a clean way of producing a hierarchy of agents, hiding complexity as inner monologues.\n",
    "2. It provides a consistent way of extracting an answer from a lengthy group chat (normally, it is not clear which message is the final response, and the response itself may not always be formatted in a way that makes sense when extracted as a standalone message).\n",
    "3. It provides a way of recovering when agents exceed their context window constraints (the inner monologue is protected by try-catch blocks)\n",
    "\n",
    "````{=mdx}\n",
    ":::info Requirements\n",
    "Install `autogen`:\n",
    "```bash\n",
    "pip install autogen[openai]\n",
    "```\n",
    "\n",
    "For more information, please refer to the [installation guide](/docs/user-guide/basic-concepts/installing-ag2).\n",
    ":::\n",
    "````"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import autogen\n",
    "\n",
    "llm_config = autogen.LLMConfig.from_json(\n",
    "    path=\"OAI_CONFIG_LIST\",\n",
    "    temperature=0,\n",
    "    timeout=600,\n",
    "    cache_seed=44,  # change the seed for different trials\n",
    ").where(model=[\"gpt-4\", \"gpt-4-0613\", \"gpt-4-32k\", \"gpt-4-32k-0613\", \"gpt-4-1106-preview\"])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "````{=mdx}\n",
    ":::tip\n",
    "Learn more about configuring LLMs for agents [here](/docs/topics/llm_configuration).\n",
    ":::\n",
    "````\n",
    "\n",
    "### Example Group Chat with Two Agents\n",
    "\n",
    "In this example, we will use an AssistantAgent and a UserProxy agent (configured for code execution) to work together to solve a problem. Executing code requires *at least* two conversation turns (one to write the code, and one to execute the code). If the code fails, or needs further refinement, then additional turns may also be needed. We will then wrap these agents in a SocietyOfMindAgent, hiding the internal discussion from other agents (though will still appear in the console), and ensuring that the response is suitable as a standalone message."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Construct the Inner-Monologue Agents\n",
    "We begin by constructing the inner-monologue agents. These are the agents that do that real work."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assistant = autogen.AssistantAgent(\n",
    "    \"inner-assistant\",\n",
    "    llm_config=llm_config,\n",
    "    is_termination_msg=lambda x: x.get(\"content\", \"\").find(\"TERMINATE\") >= 0,\n",
    ")\n",
    "\n",
    "code_interpreter = autogen.UserProxyAgent(\n",
    "    \"inner-code-interpreter\",\n",
    "    human_input_mode=\"NEVER\",\n",
    "    code_execution_config={\n",
    "        \"work_dir\": \"coding\",\n",
    "        \"use_docker\": False,\n",
    "    },\n",
    "    default_auto_reply=\"\",\n",
    "    is_termination_msg=lambda x: x.get(\"content\", \"\").find(\"TERMINATE\") >= 0,\n",
    ")\n",
    "\n",
    "groupchat = autogen.GroupChat(\n",
    "    agents=[assistant, code_interpreter],\n",
    "    messages=[],\n",
    "    speaker_selection_method=\"round_robin\",  # With two agents, this is equivalent to a 1:1 conversation.\n",
    "    allow_repeat_speaker=False,\n",
    "    max_round=8,\n",
    ")\n",
    "\n",
    "manager = autogen.GroupChatManager(\n",
    "    groupchat=groupchat,\n",
    "    is_termination_msg=lambda x: x.get(\"content\", \"\").find(\"TERMINATE\") >= 0,\n",
    "    llm_config=llm_config,\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Construct and Run the SocietyOfMind Agent\n",
    "We now wrap the inner group-chat with the SocietyOfMind Agent, and create a UserProxy to talk to it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from autogen.agentchat.contrib.society_of_mind_agent import SocietyOfMindAgent\n",
    "\n",
    "task = \"On which days in 2024 was Microsoft Stock higher than $370?\"\n",
    "\n",
    "society_of_mind_agent = SocietyOfMindAgent(\n",
    "    \"society_of_mind\",\n",
    "    chat_manager=manager,\n",
    "    llm_config=llm_config,\n",
    ")\n",
    "\n",
    "user_proxy = autogen.UserProxyAgent(\n",
    "    \"user_proxy\",\n",
    "    human_input_mode=\"NEVER\",\n",
    "    code_execution_config=False,\n",
    "    default_auto_reply=\"\",\n",
    "    is_termination_msg=lambda x: True,\n",
    ")\n",
    "\n",
    "user_proxy.initiate_chat(society_of_mind_agent, message=task)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Remarks\n",
    "\n",
    "There are a few things to notice about this output:\n",
    "- First, the user_proxy sent only one message to the society_of_mind agent, and received only one message in response. As far as it is concerned, the society_of_mind agent is the only agent in the chat.\n",
    "- Second, the final response is formatted in a way that is standalone. Unlike the prior response, it makes no reference of a previous script or execution, and it lacks the TERMINATE keyword that ended the inner monologue."
   ]
  }
 ],
 "metadata": {
  "front_matter": {
   "description": "Explore the demonstration of the SocietyOfMindAgent in the AG2 library, which runs a group chat as an internal monologue, but appears to the external world as a single agent, offering a structured way to manage complex interactions among multiple agents and handle issues such as extracting responses from complex dialogues and dealing with context window constraints.",
   "tags": [
    "orchestration",
    "nested chat",
    "group chat"
   ]
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
